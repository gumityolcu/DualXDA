{
    "model": "unsloth/Llama-3.2-1B",
    "training_file": "/home/weckbecker/coding/DualXDA/src/dataset/ag_news/train_full.jsonl",
    "test_file": "/home/weckbecker/coding/DualXDA/src/dataset/ag_news/test.jsonl",
    "finetuned_model_id": "foo/foo",
    "max_seq_length": 128,
    "load_in_4bit": false,
    "push_to_private": true,
    "epochs": 0.2,
    "max_steps": -1,
    "per_device_train_batch_size": 12,
    "per_device_eval_batch_size": 12,
    "gradient_accumulation_steps": 1,
    "warmup_steps": 5,
    "learning_rate": 1e-04,
    "logging_steps": 50,
    "eval_steps": 2, 
    "eval_strategy": "steps",
    "do_eval": true, 
    "optim": "adamw_torch",
    "weight_decay": 0.01,
    "lr_scheduler_type": "linear",
    "seed": 3,
    "beta": 0.1,
    "save_steps": 2000,
    "output_dir": "/home/weckbecker/coding/DualXDA/src/models/llama2-ag_news/train_dualda_top_3_C-3/",
    "num_labels": 4,
    "order_by_attribution": true,
    "attribution_file": "../explanations/ag_news/llama/dualda_0.001_v3/DualDAExplainer-0.001_all",
    "descending_attribution": true
}
